1. 目录
1	Hive背景以及应用场景	1
1.1	Hive常见应用场景	1
1.1.1	日志分析	1
1.1.2	其他场景	1
1.2	为什么要使用Hive	1
1.3	有了Hive,还需要自己写MapReduce吗	1
1.3.1	Hive的HQL表达能力有限	1
1.3.2	Hive效率较低	1
2	Hive基本架构	2
2.1	Hive的组成	2
3	Hive部署	3
4	Hive使用	4
4.1	Hive数据模型	4
4.2	HIve数据类型	4
4.3	Hive数据定义语句(DDL)	5
4.4	Hive默认分隔符	5
4.4.1	修改分隔符	6
4.4.2	应用举例	6
4.5	加载数据:	7
4.5.1	Load data	7
4.6	Select语句	8
4.7	Join语句	8
4.8	Order by和Sort by	9
4.9	Distribute by与CLuster by	9
4.10	UDF(User Defined Function)	9
5	Hive案例分析	10
5.1	日志分析系统	10
5.1.1	日志预处理	10
5.1.2	创建Hive表	11
5.1.3	将数据导入表中	11
5.1.4	编写HQL,分析数据	11

1 Hive背景以及应用场景
1. 由facebook开源,最初用于解决海量结构化的日志数据统计问题
ETL(Extracition-Transformation-Loading)工具
2. 构建在hadoop之上的数据仓库
数据计算使用MR,数据村塾使用HDFS
3. Hive定义了一种类型SQL查询语言--HQL
类似于SQL,但很不同
4. 通常用于进行离线数据处理(采用MapReduce);
5. 可认为是一个HQLMR的语言翻译器
1.1 Hive常见应用场景
1.1.1 日志分析
统计网站一个时间段内的pv,uv
多维度数据分析
大部分互联网公司使用Hive进行日志分析,包括百度,淘宝等
1.1.2 其他场景
海量结构化数据离线分析
低成本进行数据分析(不直接编写MR)
1.2 为什么要使用Hive
1. 简单,容易上手
提供了类SQL查询语言HQL;
2. 为超大数据集设计的计算/扩展能力
MR作为计算引擎,HDFS最为存储系统
3. 统一的数据管理
可与pig,Presto等共享
1.3 有了Hive,还需要自己写MapReduce吗
1.1.3 Hive的HQL表达能力有限
迭代算法无法表达(比如pagerank)
有些复杂运算用HQL不易表达
1.1.4 Hive效率较低
Hive自动生成MapReduce作业,通常不够智能
HQL调优困难,粒度较粗
可控性差
2 Hive基本架构




2.1 Hive的组成
1. 用户接口
包括CLI, JDBC/ODBC, WebUI
2. 元数据存储(metastore)
默认存储在自带的数据库derby(嵌入式的)中,线上是有时一般换为mysql
3. 驱动器(Driver)
解释器,编译器,优化器,执行器
4. Hadoop
用MapReduce进行计算,用HDFS记性存储
3 Hive部署

Hive部署--实验环境


生产环境


4 Hive使用
4.1 Hive数据模型

1. Database
2. Table
3. Partition
4. File
4.2 HIve数据类型
1. Primitive
1) tinyint/smallint/int/bigint
2) boolean
3) double/float
4) string
2. Array
3. Map
4. Struct
5. timestamp(v0.8.0+)
6. binary(v0.8.0+)





4.3 Hive数据定义语句(DDL)


4.4 Hive默认分隔符

例如:
上标中记录的形式如下;


1.1.5 修改分隔符

1.1.6 应用举例
某个网站日志格式如下:

表定义如下:

4.5 加载数据:

分析数据:
select log_time.* from logs;
Partitioned by

Load data
Insert
Multiple insert

1.1.7 Load data
当数据被加载至表中是,不会对数据进行任何转换.
Load操作知识将数据复制/移动至Hive表对应的位置.
默认每个表一个目录,比如数据库dbtest中,表名为tbtest,则数据存放位置为:
${metastore.warehouse.dir}/dbtest.db/tbtest
metastore.warehouse.dir默认值是/usr/hive/warehouse

Hive不支持Update操作
底层存储是HDFS,HDFS本身不支持update操作
4.6 Select语句

不支持having和exist in操作
4.7 Join语句

不支持所有非等值的连接
4.8 Order by和Sort by
Order by
只会有一个reduce task
数据全局有序
速度可能比慢
Strict模式下,必须与limit连接
Sort by
可以有多个reduce task
数据的各个分片有序
通常与distribute by
4.9 Distribute by与CLuster by
distribute by
相当于MapReduce中的partitioner,默认是基于hash实现的;
与sort by连用,可发挥很好的作用
举例

cluster by
当distribute by与sort by(降序)连用,且跟随的字段相同,可使用distribute by简写;
举例

4.10 UDF(User Defined Function)
用户可以自动以函数对数据进行处理
如下定义:


5 Hive案例分析
5.1 日志分析系统
1. 原始日志由一定的格式,包含访问时间,访问URL,ip等信息
2. 原始睿智通常不直接交个hive处理,而是经过一个清晰和转化过程
1) 转换成与hive表对应的格式
2) 一般通过写Hadoop Streaming作业实现,可使PHP, Python等语言.
通过MapReduce作业将日志转化为固定格式
1.1.8 日志预处理
通过一个Streaming作业,将日志准话为key=value的形式

1.1.9 创建Hive表

1.1.10 将数据导入表中
load data inpath ‘/home/log/result_hive/*’ into result
1.1.11 编写HQL,分析数据
统计17:00到18:00日志中的 独立ip数
